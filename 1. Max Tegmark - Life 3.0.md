一段與Max Tegmark的對話，作為MIT課程“通用人工智能”的一部分。[視頻版已被上傳至YouTube](https://www.youtube.com/watch?v=Gi8LUnhP5yU&list=PLrAXtmErZgOdP_8GztsuKi9nrraNbKKp4)。他是MIT的物理教授，未來生命學院的聯合創辦人，以及《生命3.0：作為人工智能時代的人類》的作者。

原帖地址：[Max Tegmark: Life 3.0 | MIT | Artificial Intelligence Podcast (lexfridman.com)](https://lexfridman.com/max-tegmark/)

Lex：作為MIT課程6.S099通用人工智能的一部分，我有幸與Max Tegmark坐下來談話。他是一位MIT教授、一位物理學家，花了大把時間研究宇宙之謎，不過他也花時間鑽研人工智能可能的益處和潛在的風險。與此同時，他是未來生命學院的聯合創辦人，是兩本書的作者，這兩本書我都非常推薦，第一本：《我們的數學世界》，第二本：《生命3.0》。他很擅長跳出常規來思考，是個很有意思的人，我非常享受跟他聊天的時光。如果你想看更多類似的視頻，請關注我的頻道，並開啟小鈴鐺。另外，去讀Max的書《生命3.0》裡第七章：目標。這是我最愛的一章。這是真正的當哲學與工程碰撞的時刻，並且以Dostoyevsky的名言開頭：人類的存在之秘不僅在於活著，還在於尋找活著的意義。最後，我認為每個失敗都獎勵我們一個學習的機會，從這個意義上講，能以一種新的、刺激的方式失敗是一件幸運的事情。在這集中我學到了一種叫做電磁干擾的東西。很明顯，當地廣播電台的音樂和對話會滲入正在記錄的音頻，以一種幾乎完全毀掉音頻的方式，這是一種非常難以排除的音源，因此，我得到一個機會學到如何在未來錄音時避免電磁干擾的方式，也學到瞭如何用Adobe Audition 和 isotope rx6 做一些音頻修復，當然了，這是一種非常難以排除的噪音，我是個工程師，但我不是音頻工程師，我們團隊裡沒人是音頻工程師。不過我們已經盡力而為。感謝你耐心聽完我扯這些，希望你還能繼續享受這個對話。

Lex：你相信在宇宙之外有別的智能體嗎？讓我們以這個簡單的問題開始。

Max：我其實有一個少數派的觀點。當我給公眾演講時，我會揮一揮手，問大家，是否在另一個地方有種智慧體。幾乎所有人都會舉手錶示認同。當我問“為什麼？”時，會有人回答：宇宙中有那麼多星系，當然會有別的智慧體存在。但我是個數字書呆子對吧，如果你仔細去計算的話，會發現結果不是那麼確定。首先，當我們說我們的宇宙時，我們聊的其實並非所有空間。比如你現在可以先把我們的“空間”扔給我，就在你身後。我們說的空間其實是光能到達的球形空間，光在大爆炸後13.8億年內到達的所有點，在球形之外還有別的空間，但我們說的宇宙其實只是球形之內的空間。所以是否有別的智慧體已經發展到建造望遠鏡和計算機的地步？我的答案其實是：沒有。智慧體出現再特定行星上的機率是一個我們無法還無法確定的數字。我們確定的是，這個數字不會很高，因為僅在中部奇異銀河就已經有超過10億的行星，其中很多比地球老。除了一些UFO信徒，沒有太多證據證明任何高等文明來過，這就是著名的費米悖論。如果你仔細計算這些數字，你會發現，如果你不知道在給定星球上有生命的概率是多少，這個概率就可能是10的-10次方、10的-20次方，10的-2次方，或任何10的冪，只要你去想，都有可能。這意味著離我們最近的鄰居可能是10的16次方米、10的17次方米、10的18次方米。不會的，當你算到10的16次方米之內時，我們大概已經知道，沒啥能比這更近了。

Lex：因為他們會發現我們。

Max：是的，他們早該發現我們了。如果足夠近，我們可能會注意到他們在做的一些工程項目。如果超過10的26次方米，那就超過這個範圍了。所以我認為可能我們是咱們村唯一懂得建造高級技術的人，同時我認為這使我們背負了很多責任。別因為技術搞砸了。我認為那些想當然認為我們搞砸了、會以某種事故、某次核戰爭或以某種方式滅絕的人想得沒那麼誇張。他們認為會發生類似星際迷航的劇情，其他生命形式會來拯救我們。我怎麼幻想這一切不重要，重要的是這些給我們一種錯誤的安全感。我認為更謹慎的說法是，讓我們感恩我們有這個機會並充分利用它，如果這一切真的取決於我們的選擇的話。

Lex：從物理學的角度看，你認為智能生命的出現從整個宇宙的統計角度來看是獨一無二的，但是從宇宙的基本物質看，出現這種智慧生命體的難度有多大？在你的討論中，像人類這樣這種能建構高等技術的智慧生命體很難被創建。

Max：我認為我們已知的是，生命從無到有的過程需要一定的技術水平。想要超越這一切，想用生命去安頓好整個宇宙的話，這中間的確有些障礙，這些障礙也可被稱作偉大的過濾器，因為它們相當難通過。這些障礙要么我們已經通過了，要么還擋在面前。我希望我們已經通過了。每次NASA宣布說他們又沒在火星上找到生命，我都很開心。太棒了！因為這意味著通過“創造生命”的障礙已經相當難。也許在火星上已經有了很低級的生命，找到了核醣體啥的，它們也是沒家的。因為如果這是真的，那麼未來真的只受我們想像力的限制，如果事實證明我們的生命等級像是大塊鑽石一樣稀有，那也挺糟糕的。也許還會碰到別的問題，像是，如果某文明在100年內獲得到先進的技術，他們就會和自己打仗，然後噗，全炸沒了。

Lex：所以，你已經研究了位於你我之間的宇宙學的宇宙。同時你也開始探索另一個宇宙，一個神秘的智慧生命的宇宙。在你的興趣和你對空間和智慧體的思考之間是否有重疊的部分？

Max：是的，當我還是個十來歲的少年時，我對最大的問題就已經很感興趣了，我認為科學世界裡最大的兩個謎團是：外面的宇宙和這裡的宇宙（手指自己的腦袋）。所以還挺自然的，我花了四分之一個世紀的時間思考這個問題，現在我沉迷於對這個問題的研究。這太酷了。我感覺時機很對。正確的時機極大地加深了我們對此的理解。

Lex：正確的探索此事的時機哈。

Max：是的。我想很多人認為智慧體是一種很神秘的事物，它只能存在於像我們這樣的生物組織中，於是將通用人工智能看作科幻。但從我一個物理學家的角度看，我是由一團夸克和電子組成的，以某種模式移動，以特定方式處理信息，再怎麼說也是一團夸克和電子。我不會因為與一個水瓶的基本組成成分不同（不同種類的夸克）而比一個水瓶更聰明吧？我由上夸克和下夸克組成，跟這個一模一樣。我的體內沒有秘密配方。唯一不同的可能是處理信息的方式。也就是說，沒有物理定律規定我們無法創造出智慧體來幫我們加強現有技術，幫我們解開我們解不開的謎團。總而言之，我們只看到了智慧體的冰山一角。

Lex：所以，你創造了percetronium這個詞，這是個假設中的物質狀態，從物理學的角度思考，什麼樣狀態的物質可以幫助你所說的主觀體驗的產生，意識的產生。那麼從物理學的角度看，你是怎麼看待意識的呢？

Max：非常好的問題。再說一次，很多人通過說服自己這是不可觸及的領域，低估了我們在這方面取得進展的能力，以為我們缺乏必要的成分，什麼意識粒子啥的。而我恰好認為我們啥都不缺。意識有意思之處恰恰在於，它帶給我們的對於色彩、聲音和情感等的令人驚嘆的主觀體驗。這不過只是一種高級的處理信息的模式。所以我想到用percetronium思考這個問題。對於任意物理系統，有意識意味著什麼，系統內粒子是怎樣的狀態，系統內的信息又是如何流動。我討厭碳基沙文主義，說什麼要有碳基才有意識。

Lex：其實內部信息處理的模式才是重要的對嗎？

Max：對啊。你可以看到這裡各種我最愛的公式，用於描述這個世界各種不同的基礎的方面。我想終有一天，正在看視頻的人會想到滿足意識的產生的信息處理模式。我確信這方面會有個大發現。因為讓我們承認吧，確實有些信息處理模式是有意識的，因為我們是有意識的。但是我們也知道有很多信息處理模式是不帶意識的。你腦子中現在正在發生的大部分信息處理都沒有意識。你的視覺系統正在接收10MB/s的信息，你的心跳調節等等事情都是無意識的。即使我只是讓你讀一下這裡寫了啥，你讀了一下，說這裡寫了啥，在讀的過程中你也不知道信息處理是如何發生的。你的意識就像正在指揮你的CEO，桌上擺著寫有最終答案的電子郵件。那麼是什麼讓這些有有無意識區別呢？我認為這既是一個科學謎團。其實我們正在MIT的實驗室裡研究這個謎團，也是個很緊急的問題。緊急是因為，如果你是急診室的醫生，如果你遇到一個反應遲鈍的病人，如果有個CT掃描儀，還有個意識掃描儀，可以掃描得出這個人是真被鎖定在綜合徵裡還是真的昏迷了？在未來，想像一下如果我們能製造出一種我們能與之良好溝通的機器。不是很離譜吧，你難道不好奇這台機器正在經歷什麼嗎？它的行為會固定得像是殭屍嗎？你更喜歡哪種？喜歡殭屍式的程序執行（這樣你就不必在關掉它時產生負罪感），或是另一種有靈魂的機器呢？

Lex：我當然更期待意識的出現。不過問題是，我們對意識的出現的擔憂與對意識本身的擔憂是一回事嗎？可以從此引出一個問題：你認為我們是否必須先理解意識是什麼，解決意識的關鍵問題才能構建一個通用人工智能係統那樣的東西嗎？

Max：不，我不這麼認為。我認為我們……即使我們不回答這個問題，我們也有可能建造出一個像樣的東西（指通用人工智能）。但是如果我們想確保構建通用人工智能是一件好事，我們最好先解決它（指通用人工智能的黑盒）。你在這裡提出了一個很好的爭議，對這個難題有3種看法。有兩派不同的觀點，兩派都認為意識產生沒有所謂的難題。一方面，有一些像丹尼爾·丹尼特這樣的人，他們說，“這是我們的意識”是胡扯，因為意識和智力是一回事，沒有區別。任何有意識的行為（哪怕出自人工智能）都是有意識的，就像我們人類一樣。然後也有很多人，包括我認識的許多頂尖AI研究人員，他們說，（人工智能的）意識是胡扯。因為機器當然永遠不會有意識。它們應被描述成殭屍。你永遠不必對你對待他們的方式感到內疚。然後還有1/3的人屬於騎牆派，包括朱利奧·托諾尼，以及克里斯多福兄弟。我會把自己算作騎牆派，認為實際上一些信息處理是有意識的，一些不是。讓我們找到可以用來確定它算不算有意識的方程。不過我想我們也許只是有點懶，有點逃避這個問題。很長一段時間裡，提到“意識”這個詞幾乎是禁忌。但是我們應該停止找藉口。這是一個科學問題，而我們甚至可以測試一些方法，測試任何對某信息處理模式做出意識有無預測的理論（思想實驗）。回到這個輔助機器人，我的意思是，所以你說你想幫助機器人做出有意識的行為，對待你，比如，和你交談。我想，如果你意識到這只是，改一改錄音機，只有殭屍和假裝的情感，你會不會感覺有點變態。你是希望它真的能感受到，還是希望它什麼都感受不到，於是不必為你對它做的事情感到內疚？

Lex：這個問題太難回答了，因為就像當你在戀愛中，你說，我愛你，而另一個人回答說，我也愛你。這就像問，是他或她真的愛你，還是只是在配合你演出？你真的不想讓他們真的愛你嗎？很難真正知道兩者之間的區別。要么一切看起來都像有意識存在，有智慧存在，有感情、激情、愛，要么一切都是假象。

Max：我能提一個問題，讓它更尖銳一點嗎？假設一個大型綜合醫院就在河對面，你要去做醫療手術，我們要做的是給你注射肌肉鬆弛劑，這樣你就不能動了，整個手術過程中你會感到難以忍受的疼痛，但你對此無能為力。但是我們會給你一種藥來抹除整個手術的記憶。你會因此變得冷靜點嗎？如果行為上一模一樣，有無意識還有區別嗎？

Lex：對。這是一個非常清晰的表達方式。從這個意義上說，體驗它就像是一種有價值的品質。所以實際上能夠有主觀的體驗，至少在這種情況下是這樣，是有價值的。

Max：我認為我們人類也有一點不好的記錄，提出這些自私的論點，認為其他實體沒有意識。人們經常說，哦，這些動物感覺不到疼痛，煮龍蝦沒關係，因為我們問它們疼不疼，它們什麼也沒說。現在有一篇論文說龍蝦在煮的時候會感到疼痛，他們在瑞士禁止這樣做。我們以前經常對奴隸這樣做，說，哦，因為他們不介意，因為他們也許不介意或者沒意識，或者女人沒有靈魂什麼的。所以當我聽到人們只是把“機器永遠不可能有經歷”作為公理時，我有點緊張。我認為這是一個非常有趣的科學問題。讓我們研究一下，試著找出是什麼讓無意識的智能行為和有意識的智能行為有所不同。

Lex：如果你想到波士顿动力公司的人或机器人有点像被某種掃帚推来推去，它开始推动这个意识问题。所以让我问一下，你认为agi系统像一些神经科学家认为的那样，需要有一个物理体现，需要有一个身体或类似身体的东西吗？

Max：不，我不這麽認爲。你的意思是爲了擁有帶意識的經歷嗎？

Lex：嗯，爲了擁有意識。

Max：我確實認為有一個身體的體驗很有幫助，可以幫助意識體了解世界上對我們人類重要的事情，那是當然。但是只要有了意識的經理，我不認為身體的體驗是必要的。想想做夢的時候，對吧？你的眼睛是閉著的，你沒有得到任何感官輸入，你沒有任何行為或移動，但是那裡仍然有一種體驗。對吧？所以很明顯，當你在夢裡看到很酷的東西時，你的經歷不是來自你的眼睛。這只是你大腦中的信息處理本身，也就是那種體驗本身。

Lex：如果我換種方式說，因為它來自神經科學，你想要有身體和物理實體，比如一個物理系統是因為你希望能夠保存一些東西。為了有一個自我，你可能會說，你需要對一個人有某種自我的體現來保存嗎？

Max：嗯，現在我們開始有點擬人化，擬人化的東西，也許談論自我保護的本能。我是說，我們和生物體有關，對吧？所以達爾文式的進化賦予了我們和其他生物自我保護的本能。因為沒有自我保護的基因從基因庫中被清除了。對吧？但是如果你建造一個通用人工智能，你可以設計的自我空間要比僅僅靠進化得到的特定自我子集大得多。通用人工智能的思想不一定要有任何自我保護的本能。它也不一定要像我們一樣個人主義。想像一下，首先，我們也非常害怕死亡。我想你可以每5分鐘回溯一次時間，然後你的飛機就要墜毀了。你就會想，哎呀，我……自從上次雲備份以來，我將失去最後5分鐘的體驗。這沒什麼大不了的。或者如果我們可以很容易地在大腦之間複製經驗。如果我們是矽基的，這很容易做到，對吧？那麼也許我們會感覺更像蜂巢思維，實際上。所以我不認為我們應該想當然地認為通用人工智能必須有任何作為阿爾法男性本能的競爭。另一方面，這真的很有趣，因為我認為有些人走到了另一個極端，說，當然，我們也不必擔心先進的AI會有這些本能，因為我們可以建造任何我們想要的東西。有一套非常好的論點可以追溯到史蒂夫·阿莫洪德羅和尼克·博斯特羅姆等人，他們指出，當我們製造機器時，我們通常帶著某種目標來製造它們。贏得這場象棋比賽，安全駕駛這輛車什麼的。一旦你把一個目標放進機器，尤其是如果它是一個開放式的目標，機器非常聰明，它會把它分解成一堆子目標。其中一個目標幾乎總是自我保護。因為如果它在這個過程中破裂或死亡，它就不會實現目標。對。假設你只建造了一點。你有一個小機器人，你告訴它去這裡的star市場給你買些食物，讓你做一頓意大利晚餐，然後有人搶劫它並試圖在路上攻擊它。那個機器人有動力去防……防止被摧毀，或直接逃跑，因為否則它會無法達成你的指令。它不怕死，但它真的很想做完晚餐，完成目標。所以它會有一種自我保護的本能。

Lex：繼續做一個合格“工具人”。

Max：對啊。不知何故，同樣，如果你給一個通用人工智能任何更雄心勃勃的目標，他們很可能想獲得更多的資源，這樣它就可以做得更好。嗯。正是出於這些子目標，我們可能無意中對通用人工智能安全性的一些擔憂。你給它一些看起來完全無害的目標，然後在你意識到之前，它也在努力做一些你不想讓它做的事情。它可能比我們聰明。太迷人了。

Lex：讓我暫停一下，因為我是以人類為中心的。你看，對死亡的恐懼是一個有價值的動力。所以你認為這是進化的產物嗎？這就是那種思維空間進化創造的。他們幾乎痴迷於自我保護，某種基因水平。你不認為有必要害怕死亡嗎？不僅僅是爲了繼續做某事而自我保護的子目標，而是更根本的，結束對目標的渴望，直接開擺保命。

Max：真有趣。我認為有必要講明是為了什麼開擺保命？

Lex：為了智力，也為了意識。你認為有限的死亡和對它的恐懼很重要嗎？

Max：所以在我回答之前，在我們就智力或意識是否有必要達成一致之前，我們應該清楚我們如何定義這兩個詞。很多非常聰明的人用非常不同的方式定義它們。我和AI專家一起參加了這個小組，他們在如何定義智力上意見不一。我將智力簡單地定義為完成複雜目標的能力。我喜歡你寬泛的定義，因為我不想成為一個碳沙文主義者。在這種情況下，不，它當然不需要對死亡的恐懼。我會說alpha go或alpha zero非常聰明。我不認為alpha zero有任何被關閉的恐懼，因為它甚至不理解它的概念。簡單來說就是意識，我是說，你當然可以想像非常簡單的經歷。如果某些植物有任何經驗，我不認為它們害怕死亡，因為無論如何它們對此無能為力。所以對死亡的恐懼對它們沒有那麼多價值。但更嚴肅地說，我認為如果你問的不僅僅是意識，而是擁有你會稱之為令人興奮的生活，在那種情況下你會感受到生活的激情並真正欣賞事物的意義，也許有這樣一個背景確實對培養對死亡的恐懼有所幫助。嘿，你的生命是有限的，讓我們充分利用有限的生命，活得充實。所以如果你知道你會永遠活著，你覺得你會改變你的（面對自己生命的態度嗎）？

Lex：確實，我是說，從某種角度來看，這將是一種令人難以置信的無聊生活。永遠活在那種鬆散的、主觀的情形中，你說的令人興奮的生活，一些其他人會理解的事情，我想，似乎它的有限性很重要。

Max：那麼，我要告訴你的好消息是，基於我們對宇宙學的理解，我們宇宙中的一切都是有限的，最終可能是有限的。

Lex：具體是什麽呢？對無限的限制會是什麼？

Max：我們可能會有一個大寒潮，或者一個大崩潰，或者一個大開裂，或者死亡，就像大爆炸或死亡泡泡一樣，所有這些都在十億年之後。所以我們當然比祖先想像的有更多的時間，但是仍然很難活到無限長，即使可利用某些漏洞實現。但是我想有些人喜歡說你應該像現在這樣在有限的生命中生活，你會在多年後死去啥的，這是最優的。這是一個很好的設想，我們應該建設我們的文明，就好像它是有限的一樣。為了安全起見，對吧？

Lex：確實如此。您將智力定義為解決複雜目標的能力。那麼你會在哪裡劃清界限呢？或者你會如何定義人類水平的智力和超人水平的智力？意識是定義的一部分嗎？

Max：不是。意識不屬於這個定義體系。我認為智力是一個光譜，有很多不同類型的目標。你可以有一個目標，成為一名優秀的國際象棋手、優秀的圍棋棋手、優秀的汽車司機、優秀的投資者、優秀的詩人等等。所以智力，就其本質而言，不是你可以衡量的，它無法被描述為一個數字，或一些整體性的優點。不，有些人更擅長這個，另一些人更擅長那個。現在，我們的機器在一些細分領域的任務上比我們好得多，比如快速乘法、記憶大型數據庫、下棋、下圍棋、開車（未來）。但是仍然沒有機器能在通用智能上與人類兒童相媲美。而是人工通用智能，AGI，你課程的名字。當然，根據它的定義，探索建造一台能像我們一樣做任何事情的機器，直到拿到”AI的古老聖杯“，這是60年代誕生的目標。當然，如果這真的實現了，我認為這將是地球生命史上最大的轉變。但它不一定帶來多巨大的影響，直到機器比我們更擅長編碼。真正巨大的變化不會在他們在所有方面都比我們好的時候到來。在那之前，當他們開始在我們做的大部分工作上變得更好時，就會有很大的變化，因為這滿足了對人類勞動力的大部分需求。當他們在AI研究上變得比我們更好時，真正巨大的變化就來了。因為現在，AI研究的時間尺度通常受到人類多年研發週期的限制。從一個軟件或iPhone或其他什麼版本到下一個版本需要多長時間？但是一旦我們有了會搞AI研發的AI，一旦谷歌可以用40000個等效的軟件取代40000名工程師，那就沒有理由研發多少年了。原則上，研發速度可以比以前快得多。未來AI和所有科學技術進步的時間尺度將由機器驅動，而不是人類。所以這一點給出了一個關於是否會有智力爆炸的難以置信的有趣爭議，工程師們稱之為奇點。這個想法的提出可以追溯到50年代，但是你可以看到艾倫·圖靈和其他人更早的時候就想到了。你問我人類水平到底是什麼，油嘴滑舌的答案是：一些在所有認知任務上都比我們好的東西。在所有認知任務上都比任何人類都好。但是真正有趣的標準，我認為實際上比這低一點：當他們在AI編程和通用學習方面比我們好的時候。如果他們想在任何方面比我們做得更好，可以通過自習來提高自己。

Lex：所以説，”更好“是一个关键词。更好指的是：面对这种复杂的目标，它能够完成。这无疑是智能的一个非常明确的定义。就像大海在上升，你可以做越来越多的事情。这真是个不错的说法，有一些暫時無法到達的高峰，但当海平面上升的时候，你就可以解决越来越多的问题。但是稍微停一下，我們要回答很多從社交網絡來一大堆問題。一群人問了一個稍微不同的關於創造力的方向，一個可能不是頂峰的東西。人類是有缺陷的，也許更好的解釋是有矛盾，在某些方面有缺陷。讓我從簡單的開始。首先，你有很多很酷的方程。讓我問一下，你最喜歡的等式是什麼？我知道他們都像你的孩子，但哪一個是最喜歡的？

Max：薛定諤公式，它是量子力學和微觀世界的萬能鑰匙。有了這個方程，我們可以檢查與原子、分子有關的一切，一直到宏觀層面。

Lex：好吧，量子力學無疑是我們世界的一個美麗而神秘的公式。所以我想問你一些問題，只是作為一個例子。它也許沒有物理那麼美，但是在數學抽象中，安德魯·威爾斯證明了費馬斯最後的理論。所以我最近才看到這個，它有點引起了我的注意。這是它被推測後的358年。所以這個非常簡單的公式，每個人都試圖證明它，每個人都失敗了。而這個人出現了，試圖證明它，然後未能證明它，並在94年再次證明了它。他說，當一切都連接在一起的那一刻，在一次採訪中說它是如此無法形容的美麗，當你最終意識到兩個猜想的連接部分的那一刻。他說，它是如此難以形容的美麗，它是如此簡單和優雅。我不明白我怎麼會錯過它。我盯著它懷疑了20分鐘。然後在白天，我走過我們系，不斷回到我的辦公桌前，看看它是否還在。我無法控制自己，我太興奮了。那是我工作生涯中最重要的時刻，我再做什麼都沒有如此大的意義了。所以那個特殊的時刻，讓我想到了美麗。讓我問問，你一生中有過這樣的時刻嗎？比如你突然有個靈感，想説，臥槽，沒毛病啊老鐵

Max：我不會把自己和安德魯·懷爾斯相提並論，但我確實有過很多類似的經歷。當我剛剛意識到物理學中一些非常酷的東西時，這是一種在大腦裏扔高閃的時刻。不過事實上，我最喜歡的一些發現，我後來意識到它們已經被更早地發現了，甚至有時發現因此而出名的人。對我來說，發表它已經太晚了。但這絲毫不會減少你意識到這一點時的情感體驗。

Lex：那麼在那一刻會發生什麼呢？那個”哇哦“時刻的你還是你嗎？那麼你認為一個智能系統、一個通用人工智能系統、一個AI系統如何才能有這樣的時刻呢？

Max：這是一個棘手的問題，因為它實際上有兩個部分，對嗎？其中之一無法被證明。不能證明你的人工智能得到的公式證明是被正確地證明的。這只是一個關於智能的問題。你能造出這麼智能的機器嗎？我認為當我們有一台機器能夠獨立地提出那種水平的證明時，可能就非常接近通用人工智能了。第二個問題是關於意識的問題。我們什麼時候才能讓機器真正有經歷，而不是像殭屍一樣？我們是否期望它對此有某種情感反應，或者任何類似於人類情感的東西，當它實現機器目標時，它確實用它來做一些非常積極、正確、崇高和有意義的事情。我當然希望，如果將來我們真的創造了與我們同時代的機器，甚至是我們的後代，我當然希望他們對生命有這種崇高的欣賞。在某種程度上，我最可怕的噩夢是，在未來的某個時候，遙遠的未來，也許我們的宇宙充滿了所有這些後生物生命，做所有這些看似很酷的事情。也許當我們的物種最終消失時，人類最後的樂趣會是，沒關係，因為我們為這裡的後代感到驕傲。我最可怕的噩夢是：我們還沒有解決意識問題，我們還沒有意識到這些都是殭屍。除了做記錄，它們什麼都不知道，它沒有任何真正的經歷，所以整件事就變成了一場沒有觀衆的演出。這就像終極殭屍啟示錄。我更希望我們有這些人可以真正欣賞。那該多麼神奇啊。

Lex：在這幅圖景中，創造力的作用是什麼？有幾個人問我關於創造力的問題。當你想到智力的時候。當然你在書的開頭講的故事涉及到創作電影等等。在我們的現代世界裡，你可以通過音樂和電影賺很多錢。所以如果你是一個智能係統，你可能想擅長這個。但這並不一定就是我所說的創造力。在海平面上升的複雜目標上，有創造性的東西重要嗎？還是我非常以人類為中心，思考創造力相對於智力有某種特殊之處？

Max：我感覺我們應該把創造力僅僅看作是智能的一個方面。并且，我們必須非常小心人類的虛榮心。我們經常想說，一旦機器能做某事，我們就試圖貶低它，說這不像真正的智能。你知道，也許如果我們要求自己寫下一個定義，我們實際上所說的創造性是什麼意思。例如，我們所說的安德魯·懷爾斯是什麼意思，他在那裡做了什麼。我們不是經常說某人做出了非常出乎意料的飛躍嗎？又不是寫一本只需一步簡單的烹飪書，比如制定規則啥的，對吧？你也許可以做。你把人們從未想過的兩件事聯繫起來，或者類似的事情。我認為這是智能的一個方面，這實際上是它最重要的一個方面。也許我們人類比傳統計算機更擅長的原因是因為它來得更自然。如果你是一個神經網絡，而不是一個傳統的基於邏輯門的計算機機器。我們身體上有所有這些連接，並在這裡激活，在那裏激活。我的預感是，如果我們建造一台機器，那種可以把任務交給它的機器。你說，嘿，我想這個月去環遊世界。你能教我通用人工智能課程嗎？然後機器說，好的，我會做的。它可以做任何你會做的事情，在我看來，會涉及到很多創造力。

Lex：所以這實際上是一個美麗的說法。我認為我們試圖抓住智力的定義恰恰是我們不知道如何構建的一切。我們作爲人類試圖找到我們擁有而機器沒有的東西。也許創造力只是其中之一。我們用來描述的詞之一。這是一個非常有趣的說法。

Max：我想我們防衛心沒必要這麽強。我不認為歷史上曾出過什麽事證明我們有多麽特殊。相反，歷史上有很多例子證明，我們試圖假裝這在某種程度上優於所有其他智慧生物。 結果卻相當糟糕，對吧？納粹德國就是這樣的，他們說他們在某種程度上比其他人優越。今天，我們仍然殘忍地對待動物，說我們不知何故太優越了，它們感覺不到疼痛。奴隸制的正當性也來自同樣的非常微弱的論點。并且，我不認為如果我們真的繼續建造人工智能，如果我們可以做得更好，我認為我們不應該試圖在某種虛假的智力優勢上找到自我價值。我認為我們應該從我們的經歷中找到我們的使命和生命的意義。對吧？即使有其他比我聰明的人，我也能有非常有意義的經歷。當我去這裡的教職員工會議時，談論一些事情的時候當然會意識到，哦，他沒有天賦，他沒天賦，他也沒天賦……我沒有天賦，這會讓我的生活變糟嗎？會讓我少跟那些人說話？當然不會。相反，我感到非常榮幸能夠與之互動，很榮幸能和其他比我更聰明的生物在一起。所以我不認為我們有任何理由不能用同樣的方法來處理智能機器。

Lex：那真有趣。所以人們不常去想這個。他們會考慮什麼時候有更智能的機器，你自然會認為這不會是一種有益的智能。你沒有意識到這可能就像諾貝爾獎的同齡人一樣。和它們交談很有趣，它們可能在某些話題上很聰明，你甚至想和它們一起喝幾杯。

Max：另外，另一個例子，我們都能理解，為什麼它不一定是一件可怕的事情。在人們面前，甚至比我們都聰明。你和我都兩歲的時候，我們的父母比我們聰明得多，對吧？我們相處得很融洽，因為他們的目標與我們的目標一致。我認為，如果我們重視一致性，這確實是我們必須解決的頭號問題。目標對齊問題。因為看到内含太多糟糕的科幻情節的好萊塢電影的人，他們擔心的是錯誤的事情，對嗎？他們擔心一些機器會突然變邪惡。這不是惡意，這是關心它的能力。顧名思義，聰明讓你非常自信。如果你有更聰明的圍棋，當然了，操作電腦是不算很智能的。當我們定義智能時，是完成圍棋獲勝的能力，它將是更聰明的人獲勝。如果你有一個人類，然後你有一個在所有方面都更聰明的通用人工智能，他們有不同的目標。猜猜誰會如願以償？對吧？我剛剛讀到一種特殊的犀牛，這種犀牛幾年前剛剛滅絕。看到犀牛媽媽和她孩子的可愛照片。為什麼我們人類把它推向滅絕？難道不是因為我們是邪惡的犀牛仇恨者嗎？總的來說，這只是因為我們的目標與犀牛的目標不一致。對犀牛來說，結果不太好，因為我們更聰明，對吧？所以我認為這非常重要，如果我們真的建造了通用人工智能，在我們釋放任何東西之前，我們必須確保它學會理解我們的目標。它採納了我們的目標，並保留了這些目標。

Lex：這個問題很酷，也很有趣，那就是作為人類的我們，能夠試著去構建我們的價值觀。所以你可以把美國憲法想像成當時人們坐下來的方式，一群白人，但這是一個很好的例子，我們應該說他們為這個國家製定了目標。很多人都同意這些目標實際上保持得很好。這是一個有趣的價值觀表述。在其他方面慘敗。對於價值一致性問題，解決方案是我們必須能夠把人類的價值觀寫在紙上或程序裡。你認為這有多難？

Max：非常困難。但這太重要了，我們真的必須盡力而為。這有兩個不同的原因，有一個技術價值調整問題，就是弄清楚如何讓機器理解我們的目標，採用它們，並保留它們。然後是它的獨立部分，哲學部分：到底是誰的價值觀？既然我們在這個星球上對價值觀沒有任何共識，那麼我們應該創造什麼樣的機制來聚集和決定，好的，什麼是好的妥協？第二個討論不能只留給像我這樣的技術書呆子，對嗎？沒錯。如果我們拒絕談論它，然後通用人工智能建立起來，誰來真正決定誰的價值觀？會有一群傢伙和一些科技公司，對嗎？他們一定能代表全人類，以至於我們想把它委託給他們嗎？僅僅因為他們擅長編程AI，他們就有資格談論未來人類的幸福嗎？我更希望這是一次真正包容的對話。

Lex：但是你認為這可能嗎？你創造了一個美麗的願景，包括多樣性、文化多樣性和討論權利、自由和人類尊嚴的各種尊重。但是達成共識有多難，你認為呢？這當然是一件非常重要的事情，我們都應該努力去做。但是你認為這可行嗎？

Max：我認為沒有比拒絕談論它更好的方法來保證失敗了，或者說，拒絕嘗試。我也認為這是一個非常糟糕的策略。讓我們先討論很長時間，然後一旦我們達成完全共識，然後我們將嘗試將其加載到某些機器中。不，我們不應該讓完美成為好的敵人。相反，我們應該從幼兒園道德開始，幾乎每個人都同意，現在就把它放進我們的機器裡。我們甚至還沒那麼做。看看任何製造客機的人，希望它在任何情況下都不會飛進建築物或山里，對嗎？然而，911劫機者能夠做到這一點。更尷尬的是，安德烈亞斯·盧比茨，這位沮喪的德國機翼飛行員，當他駕駛客機進入阿爾卑斯山，造成100多人死亡時，他只是告訴自動駕駛儀去做，他告訴該死的電腦把高度改為100m。即使它有GPS，地圖，一切，電腦只是説，好吧。所以我們應該採取這些非常基本的價值觀，然而，問題不在於我們不同意，而在於我們一直懶得嘗試把它放進我們的機器裡，確保從現在開始帶著腦子飛，如今飛機裡面都有電腦吧，但我們一直拒絕讓飛機帶著我們的基本價值觀飛行，進入安全模式，也許鎖上駕駛艙門，去最近的機場。在我們的世界裡，還有很多其他的技術，它真的開始出現，非常及時地引入一些像這樣的非常基本的價值觀，甚至在汽車上。到目前為止，我們已經遭受了足夠多的車輛恐怖襲擊。如果你把卡車和貨車開到行人身上，這根本不算是一個瘋狂的想法，只是要把硬件連到車裡罷了。因為總會有人出於某種原因想傷害別人，但是大多數人沒有技術專長來弄清楚如何解決這樣的問題，所以汽車才做不到。讓我們幫汽車一把。

Lex：這是一個很好的觀點。不追求完美，有很多事情是很多世界上大多數人都同意的。讓我們從這些基本價值觀開始吧。

Max：一旦我們從那裡開始，我們也會養成這樣的習慣。好吧，我們還應該在這裡放什麼？進行這些討論？這應該是一個循序漸進的過程。

Lex：太棒了。但這也意味著描述這些東西並向機器描述它。有一件事我們與Stephen Wolfram進行了一些討論。我不確定你是否認識Stephen Wolfram……

Max：我認識，挺熟的。

Lex：他搞了很多東西，像是元胞自動機，這些簡單的可計算的東西，這些計算系統。他提到我們可能已經在這些系統中，已經有了帶有通用人工智能的東西，意思是，我們只是還沒發現它，因為我們不能和它溝通。所以如果你給我這個機會試著至少從中形成一個問題，我認為這是一個有趣的想法，我們可以有智能係統，但是我們不知道如何向他們描述一些東西，他們也不能和我們交流。我知道你在做一些可以解釋的AI，試圖讓AI解釋它自己。那麼你的想法是什麼？自然語言處理或其他交流方式？ AI如何向我們解釋？我們如何向它解釋一些事情？對機器？或者你有不同的想法。

Max：所以你的問題有兩個不同的部分？其中一個與交流有關，這非常有趣。另一個是，我們是否已經造出了通用人工智能，但是還沒發現它。關於這點我不同意，我不認為有任何自動機或任何東西，或者互聯網本身或任何東西算是通用人工智能。它並沒有真正做到我們人類能做得更好的一切。我想通用人工智能誕生的那一天，我們很快就會注意到。我們甚至可能在它出現之前會注意到它。因為在很大程度上。但是對於第二部分……

Lex：很抱歉，我先插個話。因為你有這種美麗的方式來表達意識，作為信息處理，你可以想到智能和信息處理，你可以想到整個宇宙，有這些粒子，這些漫遊的系統擁有這種信息處理能力。你不認為存在什麼東西有能力像我們人類一樣處理信息，不認爲存在這種需要被連接才能被理解的東西嗎？這似乎有點哲學，但有一些令人信服的想法，即信息處理能力已經存在。重點應該更多地放在與之交流上。

Max：我同意。從某種意義上說，硬件處理能力已經存在。因為我們的宇宙本身，你可以把它想像成一台計算機。它不斷計算什麼水波，它是如何轉移水波和查爾斯河的。以及如何移動空氣分子。賽斯·勞埃德（我的同事）指出，你甚至可以，以一種非常嚴謹的方式，把我們的整個宇宙想像成一台量子計算機。很明顯，我們的宇宙支持這種驚人的處理能力，因為你甚至可以說我們正生活在物理計算機中，對嗎？我們甚至可以製造筆記本電腦之類的東西。所以很明顯力量是存在的。只是自然界擁有的大部分計算能力，在我看來，有點浪費在無聊的事情上，比如在一個沒人注意的地方模擬另一個海浪。對。所以從某種意義上說，生命所做的，我們建造計算機時所做的，就是重新引導自然界正在做的所有計算，去做重複一次海浪更有趣的事情，做些很酷的事情。所以原始硬件能力是存在的。甚至就像計算一樣，接下來的5秒鐘在這個水瓶裡會發生什麼？這需要大量的計算。如果你在人類電腦上做這件事，但其實一個水瓶就能做到了。但這並不意味著這個水球有通用人工智能。因為通用人工智能的意思是它也應該能夠寫我的書，做這個採訪。我認為這不僅僅是溝通問題。

Lex：雖然佛教徒說當他們看水的時候，能看到一些美感和深度

Max：溝通也很重要。因為，我的意思是，我的工作的一部分是當老師，我認識一些非常聰明的教授，不過他們很難交流。他們想出了所有這些絕妙的主意，但是要和別人交流，你還必須能夠模擬他們的想法。

Lex：是的。

Max：同理心建立得足夠好，理解他們的思維模式，你可以說他們會理解的話。這是相當困難的。這就是為什麼今天，如果你有一台能診斷癌症的電腦，你問它，你為什麼說我應該做手術？如果它只能回复：我接受了5TB數據的訓練，這是我的診斷。歪比巴伯。這並沒有真正灌輸給我們很多信心。所以我認為我們在溝通方面有很多工作要做。

Lex：你在做一些可以解釋的AI。你認為最有希望的途徑是什麼？它主要是關於自然語言處理的Alexa問題嗎？能夠真正使用人類可解釋的交流方式？所以能夠與系統對話並與您對話？還是有一些更基本的問題。

Max：我想是你提到的全部。自然语言的前景显然很重要，但它们也存在一些基本的問題。比如如果你下棋，如果你看alpha zero下的棋，它們簡直讓人大吃一驚，真的很漂亮。如果你問它是怎麼做到的？以僵尸和其他人的身份從內心深處與他們交談。他們最終能給你的只是大概，給你定義神經網絡的矩陣。你可以盯著這些數字，直到你的臉變藍，你永遠也搞不明白它為什麼會這麼做。即使你有自然語言處理，他們也可以用人類語言告訴你，哦，五，七，二，八，還是沒什麼用。所以我認為有一系列有趣的挑戰涉及到如何進行智能計算，並將其轉化為同樣好、同樣智能的東西，但這更容易理解。我認為這非常有價值，因為我認為當我們讓機器掌管我們世界上越來越多的基礎設施時，股票市場交易，武器系統等等。至關重要的是，我們可以信任這些為所欲為的人工智能。信任真的來自理解，對嗎？以一種非常基本的方式。這就是我研究這個的原因。因為我認為如果我們越有希望確保機器已經採納了我們的目標，並且他們會保留這些目標，我認為這種信任需要基於你能真正理解的事情。即使是自動駕駛汽車，對吧？如果有人只是告訴你它已經接受了大量數據的訓練，而且從未崩潰，這比有人真的有證據更讓人放心。也許這是一個計算機驗證的證據，但在任何情況下，這輛車都不會突然轉向迎面而來的車流。

Lex：這種信息有助於建立信任，並有助於建立目標的一致性。至少意識到你的目標和價值觀是一致的。

Max：我認為即使是在非常短的時間內，如果你看看今天，對吧，這種絕對可悲的網絡安全狀況，我們30億雅虎賬戶，總結了幾乎所有美國人的信用卡等等，這就是為什麼會發生這種情況？它最終會發生，因為沒有人完全理解我們的軟件是如何工作的。這就是為什麼我們還沒發現漏洞。我認為AI可以非常有效地用於進攻和黑客攻擊，但它也可以用於防禦。自動驗證和創建以不同方式構建的系統，進而可以實際證明有關它們的事情，這很重要。

Lex：那麽，說到沒人理解其工作機制的軟件，當然，很多人會問到你的論文，你對為什麼深度和廉價學習如此有效做了些研究，那是論文，但你對深度學習有什麼想法？我們自己大腦的這些簡化模型已經能夠做一些成功的感知工作，模式識別工作，現在有了alpha zero等等，做一些聰明的事情。你對這些研究的承諾限制有什麼看法？

Max：我認為有許多非常重要的見解，我們可以從這些成功中吸取非常重要的教訓。其中之一是當你觀察人類的大腦時，你會發現它非常複雜。 10到11個神經元，有所有這些不同種類的神經元，等等，等等。關於我們有幾十種不同種類的神經元是否真的是智能所必需的，已經有了長時間的爭論。我認為，我們現在可以相當令人信服地回答這個問題。不是的，只擁有一種就足夠了。如果你掀開alpha zero的引擎蓋看看，那裏只有一種神經元，而且簡單得可笑，只有簡單的數學關係。就像物理一樣，不是你有一種含有波的氣體，重要的不是分子的細節性質，而是某種程度上的集體行為。同樣，這個更高層次的網絡結構並不重要。我認為我們的大腦是如此復雜混亂，因為它不僅僅是為了變得聰明而進化的。它也參與了自我組裝和自我修復，並且可以進化。我覺得這很優雅。我的預感是，在我們完全理解大腦是如何工作之前，我們就會明白如何建造通用人工智能，就像我們早在能夠製造機械鳥之前就知道如何製造飛行機器一樣。

Lex：你給出了一個很棒的例子。正是如此，飛機在飛行方面做得很好，但沒有真正模仿鳥類飛行。

Max：即使是現在，100年後。你看過Ted Talk上德國機械鳥的那集嗎？去看看那集，太神奇了。但即使在那之後，對吧，我們仍然不用機械鳥飛行。因為這是我們想出來的方法更簡單，也更符合我們的目的。我想在通用人工智能領域可能也是一樣的。這是一個教訓。另一個教訓是我們論文提到的。首先，作為一名物理學家，我覺得這很有趣，人工神經網絡之間實際上有著非常密切的數學關係。我們在物理學中研究的很多東西都有書呆子式名字，比如重整化群方程、漢密爾頓量和亞達量。當你更仔細地看這個的時候，一開始我想，哇，這裡有些說不通啊，因為我們知道，即使你想建立一個超級簡單的神經網絡，區分貓的圖片和狗的圖片，我們現在可以做得很好很好。但是如果你稍微想一想，你會說服自己這一定是不可能的，因為如果我有一百萬像素，即使每個像素只是黑色或白色，一百萬種可能的圖像比它們在我們宇宙中的原子要多得多，對嗎？然後對每一個可能性，我都要指定一個數字，也就是它是狗的概率。對吧？圖像的任意函數是一個比我們宇宙中的原子還多的數字列表。所以很明顯，我們無法將其存儲在我的GPU或計算機的引擎蓋下，但不知何故，這個函數是有效的。這意味著什麼呢？嗯，這意味著在所有你可以用神經網絡解決的問題中，幾乎所有的問題都不可能用一個合理大小的問題來解決。但是我們在論文中展示的是，所有問題的細分領域，那種問題，你可能提出的所有問題中我們真正關心的一部分，考慮到物理定律，也是無窮小的一部分。令人驚訝的是，我們提出的問題和人工智能在合理大小下擬合出的有效函數所代表的問題基本上是相同的部分。

Lex：是啊，就像我們的世界是被創造出來一樣，太巧了。

Max：但是你可以說也許是世界是為我們創造的。我有一個更溫和的解釋，那就是進化，以及，神經網絡正是出於這個原因提出質疑。因為這種特殊的架構，與你筆記本電腦中的架構相反，非常好。適應解決自然不斷給我們祖先帶來的問題。所以這就說得通了，為什麼我們一開始就有大腦呢？它能夠對未來做出預測等等。如果我們有一個永遠無法解決的糟糕系統，它就無法解決人類要面對的問題。所以這是一個，我認為是個非常美麗的事實。我們在較早的研究中就意識到這，更深層次的網絡是好的。另外我們能夠展示一個額外的很酷的事實，那就是即使是非常簡單的問題，比如，假設我給你1000個數字，讓你把它們相乘。您可以編寫幾行代碼。嘣，寫完了。如果你只是想用一個只有一個隱藏層的神經網絡來做到這一點，雖然你可以做到，但是你需要2的1000次冪個神經元來讓1000個數字相乘，這也同樣比我們宇宙中的原子還多。但是如果你讓自己把它做成多層的深度網絡，你只需要4000個神經元。這是完全可行的。

Lex：真有趣。在另一種架構類型上，你之前提到了薛定諤方程。你對量子計算以及這種計算單元在創建智能係統中的作用有什麼看法？

Max：